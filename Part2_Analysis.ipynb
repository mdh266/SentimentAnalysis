{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis, Part 2: NLP With Spark On Google Cloud\n",
    "---------------\n",
    "\n",
    "__[1. Introduction](#bullet1)__\n",
    "\n",
    "__[2. Creating A GCP Hadoop Cluster ](#bullet2)__\n",
    "\n",
    "__[3. Getting Data From An Atlas Cluter](#bullet3)__\n",
    "\n",
    "__[4. Basic Models With Spark PiplineModels](#bullet4)__\n",
    "\n",
    "__[5. Stemming With Custom Transformers](#bullet5)__\n",
    "\n",
    "__[6. N-Grams And Parameter Tunning With Cross Validation](#bullet6)__\n",
    "\n",
    "__[7. Conclusions](#bullet7)__\n",
    "\n",
    "\n",
    "## Introduction  <a class=\"anchor\" id=\"bullet1\"></a>\n",
    "--------------\n",
    "\n",
    "In the <a href=\"http://michael-harmon.com/blog/SentimentAnalysisP1.html\">first part</a> of this two part blog post I went over the basics of ETL with PySpark and MongoDB.  In this second part I will go over the actual modeling aspect of Sentiment Anlysis using <a href=\"https://spark.apache.org/docs/latest/ml-guide.html\">SparkML</a> (aka MLlib it seems the name is changing).  Specifically, well be using <a href=\"https://spark.apache.org/docs/latest/ml-pipeline.html\">MLPipelines</a> and <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\">Logistic Regression</a> to build a basic linear classifier for sentiment.  Then well introduce a custom <a href=\"https://spark.apache.org/docs/1.6.2/ml-guide.html#transformers\">Transformer</a> class which uses the <a href=\"https://www.nltk.org/\">NLTK</a> to performing stemming.  Lastly, well inroduce N-grams and go over <a href=\"https://spark.apache.org/docs/latest/ml-tuning.html\">hyper-parameter tunning</a> with cross-validation. The point of this post *is not too build the best classifier on a huge dataset, but rather to show how to piece together advanced concepts into a ML Pipeline using PySpark.*\n",
    "\n",
    "That said we will continue to use the 1.6 million <a href=\"https://www.kaggle.com/kazanova/sentiment140\">tweets</a> from Kaggle which I loaded onto my <a href=\"https://www.mongodb.com/cloud/atlas\">Atlas MongoDB</a> cluster with the Spark job that was discussed in the last post.  While 1.6 million tweets doesn't necessitate a distributed environment, using PySpark on this datset was a little too much my whimpy 2013 Macbook Air and I needed to use a more powerful machine.  Luckily <a href=\"https://cloud.google.com/\">Google Cloud Platform</a> (GCP) gives everyone free credits to start using their platform and I was able to use Spark on a <a href=\"https://hadoop.apache.org/\">Hadoop</a> cluster using <a href=\"https://cloud.google.com/dataproc/\">dataproc</a> and <a href=\"https://cloud.google.com/datalab/\">datalab</a>. \n",
    "\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "\n",
    "## Creating A GCP Hadoop Cluster  <a class=\"anchor\" id=\"bullet2\"></a>\n",
    "---------\n",
    "I have been using Hadoop and Spark for quite some time now, but have never spun up my own cluster and gained a new found respect for Hadoop admins.  Google does make the process easy, but I had to ask a friend for help.  Between getting the correct version of Python as well as the correct version of NLTK on both the driver and worker nodes, the correct MongoDB connector for PySpark 2.3.2 and the time it takes to spin up and shut down a cluster I was very much over configuting clusters on my own.  I want to say that made me a better person or atleast data scientist, but I'm not so sure. :)\n",
    "\n",
    "On the GCP free trial I could only pass use two worker nodes and the command to create a Hadoop clsuter with two nodes is shown below:\n",
    "\n",
    "![](images/CreateCluster.png)\n",
    "\n",
    "You can see the connector for MongoDB as well as the version of Python in the strings above.  The bash scripts reference in my Google storage bucket for this project can be seen in my repo <a href=\"https://github.com/mdh266/TwitterSentimentAnalysis/tree/master/GCP\">here</a>.  After the cluster is created we  can ssh onto the master node by going to the console and click on \"*Compute Enginee* tab.  You will see a page like the one below:\n",
    "\n",
    "![](images/MasterNode.png)\n",
    "\n",
    "We can ssh on the master node using the ssh tap to the right of the instance name **mikescluster-m**.  The \"-m\" signifies it is the master node while the other instances have \"-w\" signifiying they are worker ndoes. After connecting to the mater node you can see all the <a href=\"https://data-flair.training/blogs/top-hadoop-hdfs-commands-tutorial/\">Hadoop commands</a> available:\n",
    "\n",
    "\n",
    "![](images/HDFS.png)\n",
    "\n",
    "However, we won't work on our Hadoop cluster through command line and connect to through Jupyter notebooks using Google <a href=\"https://cloud.google.com/datalab/\">datalab</a>. This involves creating an ssh-tunnel and proxy for Chrome, both of which I had no idea how to do, but luckily had friend walk me through it.  The bash scripts I used to do these last two steps are located in my repo <a href=\"https://github.com/mdh266/TwitterSentimentAnalysis/tree/master/GCP\">here</a>. After those steps were completed we can just go to the address\n",
    "\n",
    "    http://mikescluster-m:8080\n",
    " \n",
    "To see the Jupyter notebooks.  Note that that notebooks are running of the master node on port 8080 and that <a href=\"https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html\">YARN</a> can be see from the same address but with port 8088.  Now that we have our Hadoop cluster up and running on GCP we need to access our data.\n",
    "\n",
    "## Getting The Dataset From An Atlas Cluster <a class=\"anchor\" id=\"bullet3\"></a>\n",
    "---------\n",
    "\n",
    "As I mentioned in the introduction I loaded the cleaned Twitter dataset into my Atlast MongoDB cluster.  The ETL job was discussed in the previous <a href=\"http://michael-harmon.com/blog/SentimentAnalysisP1.html\">post</a> and in this post I will just show how to connect PySpark to the MongoDB database.  The only thing I will note is that to keep my collection with the limits of the free tier of Atlas I had to store the data as strings and not tokenized, so we'll do that again here.\n",
    "\n",
    "First step, however, is that we need to create a connection url string containing the cluster address, user info, as well as database and collection name in the dictionary below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_conn = {\"address\"    : \"harmoncluster-xsarp.mongodb.net/\", \n",
    "              \"db_name\"    : \"db_twitter\",\n",
    "              \"collection\" : \"tweets\",\n",
    "              \"user\"       : \"\",\n",
    "              \"password\"   : \"\"}\n",
    "\n",
    "url   = \"mongodb+srv://{user}:{password}@{address}{db_name}.{collection}\".format(**mongo_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we read documents the collection using the <code>spark.read</code> command passing in that we are using MongoDB as the format and the url as our option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "          .format(\"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "          .option(\"uri\",url)\\\n",
    "          .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, while the data hasn't quite been pulled from the source yet we would seen an error if the was a mistake in our connection string.  While we have not all the document from the Atlas cluster to our Hadoop cluster we have pulled metadata on the collection and can infer schema using the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- sentiment: integer (nullable = true)\n",
      " |-- tweet_clean: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that each document has an <code>id</code>, <code>sentiment</code> and the cleaneed tweet, <code>tweet_clean</code>.  We re tokenize the clean tweets and rename the sentiment column of our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer(inputCol  = \"tweet_clean\",\n",
    "                      outputCol = \"tokens\")\n",
    "\n",
    "df2 = tokenizer.transform(df)\\\n",
    "               .select(\"tokens\",\"sentiment\")\\\n",
    "               .withColumnRenamed(\"sentiment\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split into training and testing sets with a seed (1234) below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df2.randomSplit([0.80, 0.20], 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the number of training tweets with positive and negative sentiment below. Note, since our well be using this dataframe multiple times in the machine learning pipelines we cache it for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[tokens: array<string>, label: int]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|638006|\n",
      "|    0|638503|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupby(\"label\")\\\n",
    "     .count()\\\n",
    "     .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the classes are well balanced with nearly half a million positive and negative teets.  We do the same for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[tokens: array<string>, label: int]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|159530|\n",
      "|    0|159963|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.groupby(\"label\")\\\n",
    "    .count()\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the classes in the test sets are well balanced.  This is great because we don't have to worry about dealing with imbalanced classes and accuracy and ROC's area under the curve (AUC) are good metrics to see how well our models are performing.\n",
    "\n",
    "Normally, I would do some exploratory data analysis on the dataset, but I given that I'm paying for time on a cluster I would rather stick to showing how to create Spark ML Pipelines in this post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pipeline Classifiers <a class=\"anchor\" id=\"bullet4\"></a>\n",
    "------------\n",
    "In this section well go over using a basic logistic regression model using Spark <a href=\"https://spark.apache.org/docs/latest/ml-pipeline.html\">MLPipelines</a> which are similar to <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">Scikit-learn Pipelines</a>.  One thing to note is that I have already tokenized my tweets before writting them to the MongoDB datbase so there is no need to use the <a href=\"https://spark.apache.org/docs/2.1.0/ml-features.html#tokenizer\">Tokenizer</a> class in any of our pipelines.\n",
    "\n",
    "\n",
    "We import the basic modules below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we instantiate our classification evalutor class and pass the label of the output column from pipeline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'areaUnderROC'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "\n",
    "# get the name of the metric used\n",
    "evaluator.getMetricName()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the <a href=\"https://en.wikipedia.org/wiki/Bag-of-words_model\">**bag of words model**</a> to build features from tweets to be feed into the model.  *In the bag-of-words model, a document (in this case tweet) is represented as \"bag\" or list of its words, disregarding grammar and ordering, but keeping the multiplicity of the words.*  A two document example is:\n",
    "\n",
    "- **D1:**  Hi, I am Mike and I like Boston.\n",
    "\n",
    "- **D2:**  Boston is a city and people in Boston like the Red Sox.\n",
    "\n",
    "From these two documents, a list, or 'bag-of-words' is constructed\n",
    "\n",
    "    bag = ['Hi', 'I', 'am', 'Mike', 'and', 'like', 'Boston', 'is', \n",
    "           'a', 'city, 'and', 'people', 'in', 'the', 'red', 'sox]\n",
    "\n",
    "\n",
    "Notice how in our bag-of-words we have dropped repetitions of the words 'I', 'is' and 'Mike', we will show how multiplicity of words enters into our model next. \n",
    "\n",
    "The bag-of-words model is mainly used as a tool of feature generation. After transforming the text into a \"bag of words\", we can calculate various measures to characterize the document.  In order to do so we have to generate a vector for each document that represents the number of times each entry in the bag of words appears in the text. The order of entries in the vector corresponds to the order of the entries in the bag-of-words list.  For example, document D1 would have a vector,\n",
    "\n",
    "    [1, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0 ,0, 0, 0, 0, 0]\n",
    "    \n",
    "while the second document, D2, would have the vector,\n",
    "\n",
    "    [0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "Each entry of the lists refers to frequency or count of the corresponding entry in the bag-of-words list.  When we have a stacked collection of (row) vectors, or matrix, where each row corresponds to a document (vector), and each column corresponds to a word in the bag-of-words list, then this will be known as our **term-frequency ($\\text{tf}$) [document matrix](https://en.wikipedia.org/wiki/Document-term_matrix)**. The general formula for an entry in the $\\text{tf}$ matrix is,\n",
    "\n",
    "$$\\text{tf}(d,t) \\,  = \\, f_{t,d}$$\n",
    "    \n",
    "where $f_{t,d}$ is the number of times the term $t$ occurs in document $d \\in \\mathcal{D}$, where $\\mathcal{D}$ is our text corpus.  We can create a term-frequency matrix using Spark's <a href=\"https://spark.apache.org/docs/latest/ml-features.html#countvectorizer\">CountVectorizer</a> class.  \n",
    "\n",
    "Most often term-frequency alone is not a good measure of the importance of a word/term to a document's topic.  Very common words like \"the\", \"a\", \"to\" are almost always the terms with the highest frequency in the text. Thus, having a high raw count of the number of times a term appears in a document does not necessarily mean that the corresponding word is more important. Furtermore, longer documents could have high frequency of terms that do not correlate with the document topic, but instead occur with high numbers solely due to the length of the document.\n",
    "\n",
    "To circumvent the limination of term-frequency, we often normalize it by the **inverse document frequency (idf)**.  This results in the **term frequency-inverse document frequency (tf-idf)** matrix.  The *inverse document frequency is a measure of how much information the word provides, that is, whether the term is common or rare across all documents in the corpus*.  We can give a formal defintion of the inverse-document-frequency by letting $\\mathcal{D}$ be the corpus or the set of all documents and $N$ is the number of documents in the corpus and $N_{t,D}$ be the number of documents that contain the term $t$ then, \n",
    "\n",
    "$$idf(t,\\mathcal{D}) \\, = \\,  \\log\\left(\\frac{N_{\\mathcal{D}}}{1 + N_{t,\\mathcal{D}}}\\right) \\, = \\, -  \\log\\left(\\frac{1 + N_{t,\\mathcal{D}}}{N_{\\mathcal{D}}}\\right) $$\n",
    "\n",
    "The reason for the presence of the $1$ is for smoothing.  Without it, if the term/word did not appear in any training documents, then its inverse-document-frequency would be $idf(t,\\mathcal{D}) = \\infty$.  However, with the presense of the $1$ it will now have $idf(t,\\mathcal{D}) = 0$.\n",
    "\n",
    "\n",
    "Now we can formally defined the term frequnecy-inverse document frequency as a normalized version of term-frequency,\n",
    "\n",
    "\n",
    "$$\\text{tf-idf}(t,d) \\, = \\, tf(t,d) \\cdot idf(t,\\mathcal{D}) $$\n",
    "\n",
    "Like the term-frequency, the term frequency-inverse document frequency is a sparse matrix, where again, each row is a document in our training corpus ($\\mathcal{D}$) and each column corresponds to a term/word in the bag-of-words list.  The $\\text{tf-idf}$ matrix can be constructed using the sklearn <a href=\"https://spark.apache.org/docs/latest/ml-features.html#tf-idf\">IDF</a> class.\n",
    "\n",
    "\n",
    "The basic pipeline we use includes:\n",
    "\n",
    "    - tokenization (done previously)\n",
    "    - creating term frequency\n",
    "    - creating term frequency inverse document frequency \n",
    "    - fitting a logistic regression model to the BOW created from the previou steps\n",
    "    \n",
    "This is all done in the short few lines below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create term frequencies from tokens\n",
    "tf1 = CountVectorizer(inputCol=\"tokens\", outputCol=\"rawFeatures\")\n",
    "\n",
    "# create tf-idfs from the term frequneies\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "# create basic logistic regression model\n",
    "lr = LogisticRegression(maxIter=20)\n",
    "\n",
    "# create basic pipeline\n",
    "basic_pipeline = Pipeline(stages=[tf1, idf, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train perform feature extraction (tf-idf) and train the model all with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1         = basic_pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have trained the pipeline model we can predict it's perfromance on the test set using the <code>transform</code> method and using the <code>evaluate</code> method of the evaluator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORE: 0.9105776502556013\n"
     ]
    }
   ],
   "source": [
    "# predict on test set\n",
    "predictions1   = model1.transform(test)\n",
    "\n",
    "# get the performance on the test set\n",
    "score1         = evaluator.evaluate(predictions1)\n",
    "\n",
    "print(\"AUC SCORE: {}\".format(score1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "91% of the area under the ROC curve is very good, but let's see if we can make easy any improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stop Words\n",
    "\n",
    "One thing people usually do is to remove stop words, i.e. common words that do not add any additional information into the model.  Examples of stop words are: 'a', 'the', 'and', etc.  We remove stop words from in our  tokens by using the <a href=\"https://spark.apache.org/docs/2.1.0/ml-features.html#stopwordsremover\">StopWordsRemover</a> class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can instantiate a new StopWordsRemover object, changing the input column name for the CountVectorizer to be the output column name of the StopWordRemover and create our new pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw  = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered\")\n",
    "tf2 = CountVectorizer(inputCol=\"filtered\", outputCol=\"rawFeatures\")\n",
    "\n",
    "stopwords_pipleline = Pipeline(stages=[sw, tf2, idf, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we train model and evaluate its performance on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORE: 0.9013580561679387\n"
     ]
    }
   ],
   "source": [
    "model2         = stopwords_pipleline.fit(train)\n",
    "predictions2   = model2.transform(test)\n",
    "score2         = evaluator.evaluate(predictions2)\n",
    "\n",
    "print(\"AUC SCORE: {}\".format(score2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in this case that AUC score went down slightly with removing stop words.  This is probably because each of the tweets was rather small (number of characters wise).  Our model was probably overfitting to stop words and giving them informational value it shouldn't.  In any case, in this post were not too concerned about the performance as showing how all the pieces of machine leanring with Spark can be tied together with pipelines.\n",
    "\n",
    "## Stemming With Customer Tranformers <a class=\"anchor\" id=\"bullet5\"></a>\n",
    "------------\n",
    "\n",
    "We will use the Natural Language Tool Kit (<a href=\"https://www.nltk.org/\">NLTK</a> ) with the Porter Stemmer for stemming.  Stemming is the process of reducing words down to their root,  for example from Wikipedia :\n",
    "\n",
    "...the Porter algorithm reduces, argue, argued, argues, arguing, and argus to the stem argu \n",
    "\n",
    "Stemming is used as an approximate method for grouping words with a similar basic meaning together.  For NLP and the bag of words model this reduces the dimension of our featur space since variations in words that would normally be counted seperately are reduced to one word that is counted collectively.\n",
    "\n",
    "\n",
    "For some reason gcloud kept installing the wrong version of NLTK and inorder to get the correct version on the driver and workers I had to install within the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: nltk==3.4 in /usr/local/envs/py3env/lib/python3.5/site-packages (3.4)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/envs/py3env/lib/python3.5/site-packages (from nltk==3.4) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: singledispatch in /usr/local/envs/py3env/lib/python3.5/site-packages (from nltk==3.4) (3.4.0.3)\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "pip install -U nltk==3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now import the NLTK to and check its version is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.__version__)\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show an example how to stemming works on a sentence by first instantiating the PorterStemmer object and tokenizing a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_tokens: ['my', 'feelings', 'having', 'studied', 'all', 'day']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "tokens         = \"my feelings having studied all day\".split(\" \")\n",
    "print(\"raw tokens: {}\".format(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can then apply the stemmer's stem function to each token in the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean tokens: ['my', 'feelings', 'having', 'studied', 'all', 'day']\n"
     ]
    }
   ],
   "source": [
    "tokens_stemmed = [stemmer.stem(token) for token in tokens]\n",
    "print(\"clean tokens: {}\".format(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to user the Porter stemmer within a PySpark ML Pipeline we must create as a <a href=\"https://spark.apache.org/docs/latest/ml-pipeline.html#transformers\">Transformer</a>.  Transformer allow us to apply non-Spark functions and transformations as stages within our MLPipeline.  We create a customer PortersStemming class which extends PySparks Transformer class, HasInputCol class and HasOutputCol class, see <a href=\"https://github.com/apache/spark/blob/master/python/pyspark/ml/param/shared.py\">here</a> for class definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import keyword_only\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param\n",
    "\n",
    "\n",
    "class PorterStemming(Transformer, HasInputCol, HasOutputCol):\n",
    "    \"\"\"\n",
    "    This comes from https://stackoverflow.com/questions/32331848/create-a-custom-transformer-in-pyspark-ml\n",
    "    Adapted to work with the Porter Stemmer from NLTK.\n",
    "    \"\"\"\n",
    "    \n",
    "    @keyword_only\n",
    "    def __init__(self, \n",
    "                 inputCol  : str = None, \n",
    "                 outputCol : str = None, \n",
    "                 min_size  : int = None):\n",
    "      \"\"\"\n",
    "      Constructor takes in the input column name, output column name,\n",
    "      plus the minimum legnth of a token (min_size)/\n",
    "      \"\"\"\n",
    "      # call Transformer classes constructor since were extending it.\n",
    "      super(Transformer, self).__init__()\n",
    "\n",
    "      #set Parameter objects minimum token size\n",
    "      self.min_size = Param(self, \"min_size\", \"\")\n",
    "      self._setDefault(min_size=0)\n",
    "\n",
    "      # set the input keywork arguments\n",
    "      kwargs = self._input_kwargs\n",
    "      self.setParams(**kwargs)\n",
    "\n",
    "      # initialize Stemmer object\n",
    "      self.stemmer  = PorterStemmer()\n",
    "\n",
    "        \n",
    "    @keyword_only\n",
    "    def setParams(self, \n",
    "                  inputCol  : str = None, \n",
    "                  outputCol : str = None, \n",
    "                  min_size  : int = None\n",
    "      ) -> None:\n",
    "      \"\"\"\n",
    "      Function to set the keyword arguemnts\n",
    "      \"\"\"\n",
    "      kwargs = self._input_kwargs\n",
    "      return self._set(**kwargs)\n",
    "    \n",
    "\n",
    "    def _stem_func(self, words  : list) -> list:\n",
    "      \"\"\"\n",
    "      Stemmer function call.\n",
    "      \"\"\"\n",
    "      # We need a way to get min_size and cant access it \n",
    "      # with self.min_size\n",
    "      min_size       = self.getMinSize()\n",
    "      # stemm that actual tokens\n",
    "      stemmed_words  = map(self.stemmer.stem, words)\n",
    "      # now create the new list of tokens by filtering out those\n",
    "      # that are not of legnth > min_size\n",
    "      filtered_words = filter(lambda x: len(x) > min_size, stemmed_words)\n",
    "\n",
    "      return list(filtered_words)\n",
    "    \n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "      \"\"\"\n",
    "      Transform function is the function that is called in the \n",
    "      \"\"\"\n",
    "      \n",
    "      out_col       = self.getOutputCol()\n",
    "      in_col        = self.getInputCol()\n",
    "\n",
    "      # create the stemming function udf by wrapping the stemmer \n",
    "      # method function\n",
    "      stem_func_udf = F.udf(self._stem_func, ArrayType(StringType()))\n",
    "      df2           = df.withColumn(out_col, stem_func_udf(df[in_col]))\n",
    "   \n",
    "      return df2\n",
    "  \n",
    "  \n",
    "    def setMinSize(self,value):\n",
    "      self._paramMap[self.min_size] = value\n",
    "      return self\n",
    "\n",
    "    def getMinSize(self) -> int:\n",
    "      return self.getOrDefault(self.min_size)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys of creating this derived class are to \n",
    "\n",
    "1. Create a <code>Param</code> in the constructor which will hold our user defined parameter names, values and default values.\n",
    "\n",
    "2. \n",
    "\n",
    "3. A <code>_transform</code> which applies a customer transformation to the <code>inputCol</code> to return a new column with name <code>outputCol</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stemming object \n",
    "stem = PorterStemming(inputCol=\"filtered\", outputCol=\"stemmed\")\n",
    "\n",
    "# create new CountVectorizer object\n",
    "tf3 = CountVectorizer(inputCol=\"stemmed\", outputCol=\"rawFeatures\")\n",
    "\n",
    "# create new pipline\n",
    "stemming_pipeline  = Pipeline(stages= [sw, stem, tf3, idf, lr])\n",
    "\n",
    "# fit and get predictions\n",
    "model3         = stemming_pipeline.fit(train)\n",
    "predictions3   = model3.transform(test)\n",
    "score3         = evaluator.evaluate(predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORE: 0.9050744113870046\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC SCORE: {}\".format(score3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too much of an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_and_step_pipeline = Pipeline(stages= [sw, stem]).fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stem = stop_and_step_pipeline.transform(train)\n",
    "test_stem  = stop_and_step_pipeline.transform(test)\n",
    "\n",
    "# cache them\n",
    "train_stem.cache()\n",
    "test_stem.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams And Parameter Tunning With Cross Validation <a class=\"anchor\" id=\"bullet6\"></a>\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import NGram\n",
    "\n",
    "bigram = NGram(inputCol=\"stemmed\",\n",
    "              outputCol=\"bigrams\",\n",
    "              n=2)\n",
    "\n",
    "tf4   = CountVectorizer(inputCol=\"bigrams\", outputCol=\"rawFeatures\")\n",
    "\n",
    "bigram_pipeline  = Pipeline(stages= [sw, bigram, tf4, idf, lr])\n",
    "\n",
    "model4           = bigram_pipeline.fit(train_stem)\n",
    "predictions4     = model4.transform(test_stem)\n",
    "\n",
    "score4           = evaluator.evaluate(predictions4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORE: 0.9258992079438101\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC SCORE: {}\".format(score4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blah blah blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "                        .addGrid(tf4.minDF, [1.0, 3.0, 5.0]) \\\n",
    "                        .build()\n",
    "     \n",
    "crossval = CrossValidator(estimator          = bigram_pipeline,\n",
    "                          estimatorParamMaps = paramGrid,\n",
    "                          evaluator          = BinaryClassificationEvaluator(),\n",
    "                          numFolds           = 3)\n",
    "\n",
    "model    = crossval.fit(train_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions   = model.transform(test_stem)\n",
    "\n",
    "score         = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORE: 0.9236064128788266\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC SCORE: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>TrainValidationSplit</code> only evaluates each parameter choice once instead of multiple times over each of the $K$ fold in <code>CrossValidator</code>.  Therefore this estimator is not as expensive as cross validation,\n",
    "but can produce less reliable results when dataset isn't large enough.  See the <a href=\"https://spark.apache.org/docs/latest/ml-tuning.html#train-validation-split\">documenation</a> for more infromation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StopWordsRemover_423599bec5871e3ffed4,\n",
       " NGram_4502beb9404a4311b4d3,\n",
       " CountVectorizer_4a988db9b1e4fcfac4fe,\n",
       " IDF_4240bcd585ec2afbe47c,\n",
       " LogisticRegression_4232bcf280c352f5096b]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'minDF: Specifies the minimum number of different documents a term must appear in to be included in the vocabulary. If this is an integer >= 1, this specifies the number of documents the term must appear in; if this is a double in [0,1), then this specifies the fraction of documents. (default: 1.0, current: 5.0)'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.stages[2].explainParam('minDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = bestModel.stages[-1].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff5c00921d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.plot(summary.roc.select('FPR').collect(),\n",
    "         summary.roc.select('TPR').collect())\n",
    "plt.xlabel('False Positive Rare')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"hdfs dfs -get model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8788837368165834\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {}\".format(summary.accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions <a class=\"anchor\" id=\"bullet7\"></a>\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis, Part 2: NLP With Spark On Google Cloud\n",
    "---------------\n",
    "\n",
    "__[1. Introduction](#bullet1)__\n",
    "\n",
    "__[2. Creating A GCP Hadoop Cluster ](#bullet2)__\n",
    "\n",
    "__[3. Getting Data From An Atlas Cluter](#bullet3)__\n",
    "\n",
    "__[4. Basic Models With Spark PiplineModels](#bullet4)__\n",
    "\n",
    "__[5. Stemming With Custom Transformers](#bullet5)__\n",
    "\n",
    "__[6. N-Grams And Parameter Tunning With Cross Validation](#bullet6)__\n",
    "\n",
    "__[7. Conclusions](#bullet7)__\n",
    "\n",
    "\n",
    "## Introduction  <a class=\"anchor\" id=\"bullet1\"></a>\n",
    "--------------\n",
    "\n",
    "In the <a href=\"http://michael-harmon.com/blog/SentimentAnalysisP1.html\">first part</a> of this two part blog post I went over the basics of ETL with PySpark and MongoDB.  In this second part I will go over the actual modeling aspect of Sentiment Anlysis using <a href=\"https://spark.apache.org/docs/latest/ml-guide.html\">SparkML</a> (aka MLlib, it seems the name is changing).  Specifically, well be using <a href=\"https://spark.apache.org/docs/latest/ml-pipeline.html\">MLPipelines</a> and <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\">Logistic Regression</a> to build a basic linear classifier for sentiment.  Then we'll introduce a custom <a href=\"https://spark.apache.org/docs/1.6.2/ml-guide.html#transformers\">Transformer</a> class which uses the <a href=\"https://www.nltk.org/\">NLTK</a> to performing stemming.  Lastly, we'll inroduce N-grams and go over <a href=\"https://spark.apache.org/docs/latest/ml-tuning.html\">hyper-parameter tunning</a> with cross-validation. The point of this post *is not too build the best classifier on a huge dataset, but rather to show how to piece together advanced concepts into a ML Pipeline using PySpark... and at the same time get reasonable results.*\n",
    "\n",
    "That said we will continue to use the 1.6 million <a href=\"https://www.kaggle.com/kazanova/sentiment140\">tweets</a> from Kaggle which I loaded onto my <a href=\"https://www.mongodb.com/cloud/atlas\">Atlas MongoDB</a> cluster with the Spark job that was discussed in the last post.  While 1.6 million tweets doesn't necessitate a distributed environment, using PySpark on this datset was a little too much my whimpy 2013 Macbook Air and I needed to use a more powerful machine.  Luckily <a href=\"https://cloud.google.com/\">Google Cloud Platform</a> (GCP) gives everyone free credits to start using their platform and I was able to use Spark on a <a href=\"https://hadoop.apache.org/\">Hadoop</a> cluster using <a href=\"https://cloud.google.com/dataproc/\">dataproc</a> and <a href=\"https://cloud.google.com/datalab/\">datalab</a>. \n",
    "\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "\n",
    "## Creating A GCP Hadoop Cluster  <a class=\"anchor\" id=\"bullet2\"></a>\n",
    "---------\n",
    "I have been using Hadoop and Spark for quite some time now, but have never spun up my own cluster and gained a new found respect for Hadoop admins.  Google does make the process easier, but I had to ask a friend for help to get things to work as I wanted.  Between getting the correct version of Python as well as the correct version of NLTK on both the driver and worker nodes, the correct MongoDB connector for PySpark 2.3.2 and the time it takes to spin up and shut down a cluster I was very much done configuting Hadoop clusters on my own.  I want to say that made me a better person or atleast data scientist, but I'm not so sure. :)\n",
    "\n",
    "To start up the Hadoop cluster I used the command below with two nodes is shown below (o the GCP free trial I could only pass use two worker nodes):\n",
    "\n",
    "![](images/CreateCluster.png)\n",
    "\n",
    "You can see the string for the MongoDB connector as well as the version of Python in the commands.  The bash scripts that I reference in my Google storage bucket for this project can be seen in my repo <a href=\"https://github.com/mdh266/SentimentAnalysis/tree/master/GCP\">here</a>.  After the cluster is created we  can ssh onto the master node by going to the console and clicking on \"*Compute Enginee* tab.  You will see a page like the one below:\n",
    "\n",
    "![](images/MasterNode.png)\n",
    "\n",
    "We can ssh on the master node using the ssh tap to the right of the instance name **mikescluster-m**.  The \"-m\" signifies it is the master node while the other instances have \"-w\" signifiying they are worker ndoes. After connecting to the mater node you can see all the <a href=\"https://data-flair.training/blogs/top-hadoop-hdfs-commands-tutorial/\">Hadoop commands</a> available:\n",
    "\n",
    "\n",
    "![](images/HDFS.png)\n",
    "\n",
    "However, we won't work on our Hadoop cluster through command line, but rather connect to the cluster through Jupyter notebooks using Google <a href=\"https://cloud.google.com/datalab/\">datalab</a>. To do this involves creating an ssh-tunnel and proxy for Chrome, both of which I had no idea how to do, but luckily had friend walk me through it.  The bash scripts I used to do these last two steps are located in my repo <a href=\"https://github.com/mdh266/SentimentAnalysis/tree/master/GCP\">here</a>. After those steps were completed we can just go to the address to see the Jupyter notebooks,\n",
    "\n",
    "    http://mikescluster-m:8080\n",
    " \n",
    "Note that that notebooks are running on the master node using port 8080 and that <a href=\"https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html\">YARN</a> can be see from the same address but with port 8088 which I'll come back to a little later.  Now that we have our Hadoop cluster up and running on Google Cloud we need to access our data.\n",
    "\n",
    "## Getting The Dataset From An Atlas Cluster <a class=\"anchor\" id=\"bullet3\"></a>\n",
    "---------\n",
    "\n",
    "As I mentioned in the introduction I loaded the cleaned Twitter dataset into my Atlast MongoDB cluster and the ETL job was discussed in the previous <a href=\"http://michael-harmon.com/blog/SentimentAnalysisP1.html\">post</a>.  In this post I won't go over the ETL process again, but will show how to connect PySpark to the Atlas cluster.  One thing to note is that to keep my collection with the limits of the free tier using Atlas I had to store the data as strings and not tokenized so we'll do have to tokenize our strings again here.\n",
    "\n",
    "The first step to connecting to the database is to create a connection url string that contains the cluster address, user info, as well as database and collection name in the dictionary below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_conn = {\"address\"    : \"harmoncluster-xsarp.mongodb.net/\", \n",
    "              \"db_name\"    : \"db_twitter\",\n",
    "              \"collection\" : \"tweets\",\n",
    "              \"user\"       : \"\",\n",
    "              \"password\"   : \"\"}\n",
    "\n",
    "url   = \"mongodb+srv://{user}:{password}@{address}{db_name}.{collection}\".format(**mongo_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we read documents the collection using the <code>spark.read</code> command passing in that we are using MongoDB as the format and the url as our option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "          .format(\"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "          .option(\"uri\",url)\\\n",
    "          .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, while the data hasn't quite been pulled from the source yet, but we would still see an error if there was a mistake in our connection string.  While we have pulled the documents from our collection on the Atlas cluster to our Hadoop cluster we have still have some metadata on the collection and can infer schema using the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- sentiment: integer (nullable = true)\n",
      " |-- tweet_clean: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that each document has an <code>id</code>, <code>sentiment</code> and the cleaneed tweet, <code>tweet_clean</code>.  Let's just pull the cleaned tweet and sentiment fields and rename `sentiment` to `label`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.select(\"tweet_clean\",\"sentiment\")\\\n",
    "        .withColumnRenamed(\"sentiment\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split into training and testing sets (using 80% of the data for training and 20% for testing) with a seed (1234) below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df2.randomSplit([0.80, 0.20], 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the number of training tweets with positive and negative sentiment below. Note, since our well be using this dataframe multiple times in the machine learning pipelines we cache it for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[tweet_clean: string, label: int]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|637317|\n",
      "|    0|639237|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupby(\"label\")\\\n",
    "     .count()\\\n",
    "     .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the classes are well balanced with over half a million positive and negative teets.  We do the same for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[tweet_clean: string, label: int]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|159635|\n",
      "|    0|159840|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.groupby(\"label\")\\\n",
    "    .count()\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the classes in the test sets are well balanced.  This is great because we don't have to worry about dealing with imbalanced classes and *accuracy and ROC's area under the curve (AUC) are good metrics to see how well our models are performing.*\n",
    "\n",
    "Normally, I would do some exploratory data analysis on the dataset, but I given that I'm paying for time on a cluster I would rather stick to showing how to create Spark ML Pipelines in this post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pipeline Classifiers <a class=\"anchor\" id=\"bullet4\"></a>\n",
    "------------\n",
    "In this section well go over using a basic logistic regression model using Spark <a href=\"https://spark.apache.org/docs/latest/ml-pipeline.html\">MLPipelines</a> which are similar to <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">Scikit-learn Pipelines</a>. We import the basic modules below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we instantiate our classification evalutor class and pass the label of the output column from pipeline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'areaUnderROC'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "\n",
    "# get the name of the metric used\n",
    "evaluator.getMetricName()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the <a href=\"https://en.wikipedia.org/wiki/Bag-of-words_model\">**bag of words model**</a> to build features for our model from tweets.  *In the bag-of-words model, a document (in this case tweet) is represented as \"bag\" or list of its words, disregarding grammar and ordering, but keeping the multiplicity of the words.*  A two document example is:\n",
    "\n",
    "- **D1:**  Hi, I am Mike and I like Boston.\n",
    "\n",
    "- **D2:**  Boston is a city and people in Boston like the Red Sox.\n",
    "\n",
    "From these two documents, a list, or 'bag-of-words' is constructed\n",
    "\n",
    "    bag = ['Hi', 'I', 'am', 'Mike', 'and', 'like', 'Boston', 'is', \n",
    "           'a', 'city, 'and', 'people', 'in', 'the', 'red', 'sox]\n",
    "\n",
    "\n",
    "Notice how in our bag-of-words we have dropped repetitions of the words 'I', 'is' and 'Mike', we will show how multiplicity of words enters into our model next. \n",
    "\n",
    "The bag-of-words model is mainly used as a tool of feature generation. After transforming the text into a \"bag of words\", we can calculate various measures to characterize the document.  In order to do so we have to generate a vector for each document that represents the number of times each entry in the bag of words appears in the text. The order of entries in the vector corresponds to the order of the entries in the bag-of-words list.  For example, document D1 would have a vector,\n",
    "\n",
    "    [1, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0 ,0, 0, 0, 0, 0]\n",
    "    \n",
    "while the second document, D2, would have the vector,\n",
    "\n",
    "    [0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "Each entry of the lists refers to frequency or count of the corresponding entry in the bag-of-words list.  When we have a stacked collection of (row) vectors, or matrix, where each row corresponds to a document (vector), and each column corresponds to a word in the bag-of-words list, then this will be known as our **term-frequency ($\\text{tf}$) [document matrix](https://en.wikipedia.org/wiki/Document-term_matrix)**. The general formula for an entry in the $\\text{tf}$ matrix is,\n",
    "\n",
    "$$\\text{tf}(d,t) \\,  = \\, f_{t,d}$$\n",
    "    \n",
    "where $f_{t,d}$ is the number of times the term $t$ occurs in document $d \\in \\mathcal{D}$, where $\\mathcal{D}$ is our text corpus.  We can create a term-frequency matrix using Spark's <a href=\"https://spark.apache.org/docs/latest/ml-features.html#tf-idf\">HashingTF</a> class. To see the difference between HashingTF and <a href=\"https://spark.apache.org/docs/latest/ml-features.html#countvectorizer\">CounterVectorizer<a/> see this <a href=\"https://stackoverflow.com/questions/35205865/what-is-the-difference-between-hashingtf-and-countvectorizer-in-spark\">stackoverflow post</a>.\n",
    "\n",
    "Most often term-frequency alone is not a good measure of the importance of a word/term to a document's topic.  Very common words like \"the\", \"a\", \"to\" are almost always the terms with the highest frequency in the text. Thus, having a high raw count of the number of times a term appears in a document does not necessarily mean that the corresponding word is more important. Furtermore, longer documents could have high frequency of terms that do not correlate with the document topic, but instead occur with high numbers solely due to the length of the document.\n",
    "\n",
    "To circumvent the limination of term-frequency, we often normalize it by the **inverse document frequency (idf)**.  This results in the **term frequency-inverse document frequency (tf-idf)** matrix.  The *inverse document frequency is a measure of how much information the word provides, that is, whether the term is common or rare across all documents in the corpus*.  We can give a formal defintion of the inverse-document-frequency by letting $\\mathcal{D}$ be the corpus or the set of all documents and $N$ is the number of documents in the corpus and $N_{t,D}$ be the number of documents that contain the term $t$ then, \n",
    "\n",
    "$$idf(t,\\mathcal{D}) \\, = \\,  \\log\\left(\\frac{N_{\\mathcal{D}}}{1 + N_{t,\\mathcal{D}}}\\right) \\, = \\, -  \\log\\left(\\frac{1 + N_{t,\\mathcal{D}}}{N_{\\mathcal{D}}}\\right) $$\n",
    "\n",
    "The reason for the presence of the $1$ is for smoothing.  Without it, if the term/word did not appear in any training documents, then its inverse-document-frequency would be $idf(t,\\mathcal{D}) = \\infty$.  However, with the presense of the $1$ it will now have $idf(t,\\mathcal{D}) = 0$.\n",
    "\n",
    "\n",
    "Now we can formally defined the term frequnecy-inverse document frequency as a normalized version of term-frequency,\n",
    "\n",
    "\n",
    "$$\\text{tf-idf}(t,d) \\, = \\, tf(t,d) \\cdot idf(t,\\mathcal{D}) $$\n",
    "\n",
    "Like the term-frequency, the term frequency-inverse document frequency is a sparse matrix, where again, each row is a document in our training corpus ($\\mathcal{D}$) and each column corresponds to a term/word in the bag-of-words list.  The $\\text{tf-idf}$ matrix can be constructed using the SparkML <a href=\"https://spark.apache.org/docs/latest/ml-features.html#tf-idf\">IDF</a> class.\n",
    "\n",
    "\n",
    "The basic pipeline we will use includes:\n",
    "\n",
    "    - tokenization\n",
    "    - creating term frequency\n",
    "    - creating term frequency inverse document frequency \n",
    "    - fitting a logistic regression model to the BOW created from the previou steps\n",
    "    \n",
    "This is all done in the short few lines below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokens from strings\n",
    "tk = Tokenizer(inputCol= \"tweet_clean\", outputCol = \"tokens\")\n",
    "\n",
    "# create term frequencies from tokens\n",
    "tf1 = HashingTF(inputCol=\"tokens\", outputCol=\"rawFeatures\", numFeatures=1e5)\n",
    "\n",
    "# create tf-idfs from the term frequneies\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=2.0)\n",
    "\n",
    "# create basic logistic regression model\n",
    "lr = LogisticRegression(maxIter=20)\n",
    "\n",
    "# create basic pipeline\n",
    "basic_pipeline = Pipeline(stages=[tk, tf1, idf, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll note that the `numFeatures=1e5` means we set our \"vocabulary\" to contain 100,000 words (see above listed stackeroverflow comment for explanation of what this means). The `minDocFreq=2.0` requires that a word or token must appear a minimum of 2 documents to be counted towards a feature.  This parameter can act as form a of regularization.  Setting this value to larger integers increases the regularization by reducing the number of words we consider. This helps to combat overfitting by eliminating words which occur very rarely so they don't influence our model.\n",
    "\n",
    "Now we can train perform tokenization, feature extraction (tf-idf) and train the model all with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1         = basic_pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have trained the pipeline model we can predict it's perfromance on the test set using the <code>transform</code> method and using the <code>evaluate</code> method of the evaluator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORE: 0.8851466578396061\n"
     ]
    }
   ],
   "source": [
    "# predict on test set\n",
    "predictions1   = model1.transform(test)\n",
    "\n",
    "# get the performance on the test set\n",
    "score1         = evaluator.evaluate(predictions1)\n",
    "\n",
    "print(\"AUC SCORE: {}\".format(score1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the accuracy on the test set. I couldn't really find any good documentation about how to do this without using the old MLlib (rdd based) library.  What made it even more confusing is that I had to use <a href=\"https://spark.apache.org/docs/2.3.2/mllib-evaluation-metrics.html\">MulticlassMetrics</a> class to evualate the binary outcome, because the `BinaryClassificationMetrics` only had AUC and for ROC curve and AUC for Precision-Recall curve.  The code snippet to get the accuracy is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.8138070271539244\n"
     ]
    }
   ],
   "source": [
    "predictedAndLabels = predictions1.select([\"prediction\",\"label\"])\\\n",
    "                                 .rdd.map(lambda r : (float(r[0]), float(r[1])))\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "metrics = MulticlassMetrics(predictedAndLabels)\n",
    "\n",
    "print(\"Test Set Accuracy: {}\".format(metrics.accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "88.5% of the area under the ROC curve and 81% accuracy pretty very good for Twitter sentiment analyis, but let's see if we can make easy any improvements with more advanced preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stop Words\n",
    "\n",
    "One trick people use as a prepocessing step in NLP to remove stop words, i.e. common words that do not add any additional information into the model.  Examples of stop words are: 'a', 'the', 'and', etc.  We will remove stops from our tokens by using the <a href=\"https://spark.apache.org/docs/2.3.2/ml-features.html#stopwordsremover\">StopWordsRemover</a> class.  We import it below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can instantiate a new StopWordsRemover object setting input column to be result of the tokenization procedure.  Notice that the input column name for the HashingTF object is the same output column name of the StopWordRemover and create our new pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw  = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered\")\n",
    "tf2 = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=1e5)\n",
    "\n",
    "stopwords_pipleline = Pipeline(stages=[tk, sw, tf2, idf, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train our new model and evaluate its performance on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORE: 0.8725249381777652\n"
     ]
    }
   ],
   "source": [
    "model2         = stopwords_pipleline.fit(train)\n",
    "predictions2   = model2.transform(test)\n",
    "score2         = evaluator.evaluate(predictions2)\n",
    "\n",
    "print(\"AUC SCORE: {}\".format(score2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how easy it was to add a new stage in our MLPipeline and train our model!\n",
    "\n",
    "We can see that the AUC for our ROC went down by a little over 1.5%.  At first I was pretty puzzled by this and spent a lot of time trying to fix it only to learn that blindly removing stop words isn't always the best practice for sentiment analysis, especially when it comes to <a href=\"http://www.lrec-conf.org/proceedings/lrec2014/pdf/292_Paper.pdf\">tweets</a>.  Since removing stopped words gave our model worse performanace, we wont use it going forward.  However, it's worth while to see examples of words that were removed.  We do this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|         tweet_clean|              tokens|            filtered|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|a and yr old both...|[a, and, yr, old,...|[yr, old, girls, ...|\n",
      "|a baby bird fell ...|[a, baby, bird, f...|[baby, bird, fell...|\n",
      "|a baby llama was ...|[a, baby, llama, ...|[baby, llama, bor...|\n",
      "|a beautiful day t...|[a, beautiful, da...|[beautiful, day, ...|\n",
      "|a bicyclist was j...|[a, bicyclist, wa...|[bicyclist, hit, ...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions2.select([\"tweet_clean\",\"tokens\",\"filtered\"]).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that words like, 'a', 'and', 'was', and 'both' were removed.  Removing stop words is more helpful for the case of <a href=\"http://michael-harmon.com/blog/NLP.html\">document classification</a>, where often the class a document belongs to is determined by a few key words and removing stop words can help to understand what those key words are. \n",
    "\n",
    "\n",
    "## Stemming With Customer Tranformers <a class=\"anchor\" id=\"bullet5\"></a>\n",
    "------------\n",
    "\n",
    "Another trick for preprocessing in NLP is stemming.  We will use the Natural Language Tool Kit (<a href=\"https://www.nltk.org/\">NLTK</a> ) with the Porter Stemmer for stemming.  Stemming is the process of reducing words down to their root,  for example from Wikipedia :\n",
    "\n",
    "...the Porter algorithm reduces, argue, argued, argues, arguing, and argus all get reduced to the stem argu \n",
    "\n",
    "Stemming is used as an approximate method for grouping words with a similar basic meaning together.  For NLP and the bag of words model this reduces the dimension of our feature space since variations in words that would normally be counted seperately are reduced to one word that is counted collectively. \n",
    "\n",
    "\n",
    "For some reason gcloud kept installing the wrong version of NLTK and inorder to get the correct version on the driver and workers I had to install within the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk==3.4\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/ed/9c755d357d33bc1931e157f537721efb5b88d2c583fe593cc09603076cc3/nltk-3.4.zip (1.4MB)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/envs/py3env/lib/python3.5/site-packages (from nltk==3.4) (1.10.0)\n",
      "Collecting singledispatch (from nltk==3.4)\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/10/369f50bcd4621b263927b0a1519987a04383d4a98fb10438042ad410cf88/singledispatch-3.4.0.3-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: nltk\n",
      "  Running setup.py bdist_wheel for nltk: started\n",
      "  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/4b/c8/24/b2343664bcceb7147efeb21c0b23703a05b23fcfeaceaa2a1e\n",
      "Successfully built nltk\n",
      "Installing collected packages: singledispatch, nltk\n",
      "  Found existing installation: nltk 3.2.1\n",
      "    Uninstalling nltk-3.2.1:\n",
      "      Successfully uninstalled nltk-3.2.1\n",
      "Successfully installed nltk-3.4 singledispatch-3.4.0.3\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "pip install -U nltk==3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import the NLTK to and check its version is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.__version__)\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get into using NLTK with PySpark let's go over an example how to stemming with the NLTK works on a simple sentence.  First instantiating the PorterStemmer object and tokenizing a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw tokens: ['my', 'feelings', 'having', 'studied', 'all', 'day']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "tokens         = \"my feelings having studied all day\".split(\" \")\n",
    "print(\"raw tokens: {}\".format(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can apply the stemmer's stem function to each token in the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean tokens: ['my', 'feel', 'have', 'studi', 'all', 'day']\n"
     ]
    }
   ],
   "source": [
    "tokens_stemmed = [stemmer.stem(token) for token in tokens]\n",
    "print(\"clean tokens: {}\".format(tokens_stemmed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the word 'feelings' has been reduced to 'feel', 'having' to 'has' and 'studied' to 'studi'.  We should note that Stemming, like stop word removing might not always be helpful in deciding the sentiment since the way a word is used might effect the sentiment.  \n",
    "\n",
    "\n",
    "Now we're ready to apply stemming in our model with PySpark and in order to user the Porter stemmer within a PySpark ML Pipeline we must create as a <a href=\"https://spark.apache.org/docs/latest/ml-pipeline.html#transformers\">Transformer</a>.  The Transformer class will allow us to apply non-Spark functions and transformations as stages within our ML Pipeline.  We create a customer `PortersStemming` class which extends the PySparks Transformer class, HasInputCol class and HasOutputCol class, see <a href=\"https://github.com/apache/spark/blob/master/python/pyspark/ml/param/shared.py\">here</a> for these class definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import keyword_only\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param\n",
    "\n",
    "\n",
    "class PorterStemming(Transformer, HasInputCol, HasOutputCol):\n",
    "    \"\"\"\n",
    "    This comes from https://stackoverflow.com/questions/32331848/create-a-custom-transformer-in-pyspark-ml\n",
    "    Adapted to work with the Porter Stemmer from NLTK.\n",
    "    \"\"\"\n",
    "    \n",
    "    @keyword_only\n",
    "    def __init__(self, \n",
    "                 inputCol  : str = None, \n",
    "                 outputCol : str = None, \n",
    "                 min_size  : int = None):\n",
    "      \"\"\"\n",
    "      Constructor takes in the input column name, output column name,\n",
    "      plus the minimum legnth of a token (min_size)/\n",
    "      \"\"\"\n",
    "      # call Transformer classes constructor since were extending it.\n",
    "      super(Transformer, self).__init__()\n",
    "\n",
    "      #set Parameter objects minimum token size\n",
    "      self.min_size = Param(self, \"min_size\", \"\")\n",
    "      self._setDefault(min_size=0)\n",
    "\n",
    "      # set the input keywork arguments\n",
    "      kwargs = self._input_kwargs\n",
    "      self.setParams(**kwargs)\n",
    "\n",
    "      # initialize Stemmer object\n",
    "      self.stemmer  = PorterStemmer()\n",
    "\n",
    "        \n",
    "    @keyword_only\n",
    "    def setParams(self, \n",
    "                  inputCol  : str = None, \n",
    "                  outputCol : str = None, \n",
    "                  min_size  : int = None\n",
    "      ) -> None:\n",
    "      \"\"\"\n",
    "      Function to set the keyword arguemnts\n",
    "      \"\"\"\n",
    "      kwargs = self._input_kwargs\n",
    "      return self._set(**kwargs)\n",
    "    \n",
    "\n",
    "    def _stem_func(self, words  : list) -> list:\n",
    "      \"\"\"\n",
    "      Stemmer function call.\n",
    "      \"\"\"\n",
    "      # We need a way to get min_size and cant access it \n",
    "      # with self.min_size\n",
    "      min_size       = self.getMinSize()\n",
    "      # stemm that actual tokens\n",
    "      stemmed_words  = map(self.stemmer.stem, words)\n",
    "      # now create the new list of tokens by filtering out those\n",
    "      # that are not of legnth > min_size\n",
    "      filtered_words = filter(lambda x: len(x) > min_size, stemmed_words)\n",
    "\n",
    "      return list(filtered_words)\n",
    "    \n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "      \"\"\"\n",
    "      Transform function is the function that is called in the \n",
    "      \"\"\"\n",
    "      \n",
    "      out_col       = self.getOutputCol()\n",
    "      in_col        = self.getInputCol()\n",
    "\n",
    "      # create the stemming function udf by wrapping the stemmer \n",
    "      # method function\n",
    "      stem_func_udf = F.udf(self._stem_func, ArrayType(StringType()))\n",
    "      df2           = df.withColumn(out_col, stem_func_udf(df[in_col]))\n",
    "   \n",
    "      return df2\n",
    "  \n",
    "  \n",
    "    def setMinSize(self,value):\n",
    "      self._paramMap[self.min_size] = value\n",
    "      return self\n",
    "\n",
    "    def getMinSize(self) -> int:\n",
    "      return self.getOrDefault(self.min_size)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys of creating this derived class are to \n",
    "\n",
    "1. Create a <code>Param</code> in the constructor which will hold our user defined parameter names, values and default values.\n",
    "\n",
    "2. \n",
    "\n",
    "3. A <code>_transform</code> which applies a customer transformation to the <code>inputCol</code> to return a new column with name <code>outputCol</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stemming, with stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stemming object \n",
    "stem = PorterStemming(inputCol=\"filtered\", outputCol=\"stemmed\")\n",
    "\n",
    "# create new CountVectorizer object\n",
    "tf3 = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\", numFeatures=1e5)\n",
    "\n",
    "# create new pipline\n",
    "stemming_pipeline  = Pipeline(stages= [tk, sw, stem, tf3, idf, lr])\n",
    "\n",
    "# fit and get predictions\n",
    "model3         = stemming_pipeline.fit(train)\n",
    "predictions3   = model3.transform(test)\n",
    "score3         = evaluator.evaluate(predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORE: 0.8675643555314847\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC SCORE: {}\".format(score3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stemming, without stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem2 = PorterStemming(inputCol=\"tokens\", outputCol=\"stemmed\")\n",
    "stem_pipeline = Pipeline(stages= [tk, stem2]).fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[tweet_clean: string, label: int, tokens: array<string>, stemmed: array<string>]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stem = stem_pipeline.transform(train)\\\n",
    "                          .where(F.size(F.col(\"stemmed\")) >= 1)\n",
    "\n",
    "test_stem  = stem_pipeline.transform(test)\\\n",
    "                          .where(F.size(F.col(\"stemmed\")) >= 1)\n",
    "\n",
    "# cache them\n",
    "train_stem.cache()\n",
    "test_stem.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+\n",
      "|         tweet_clean|label|              tokens|             stemmed|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "|a and yr old both...|    1|[a, and, yr, old,...|[a, and, yr, old,...|\n",
      "|a baby bird fell ...|    0|[a, baby, bird, f...|[a, babi, bird, f...|\n",
      "|a baby llama was ...|    0|[a, baby, llama, ...|[a, babi, llama, ...|\n",
      "|a beautiful day t...|    1|[a, beautiful, da...|[a, beauti, day, ...|\n",
      "|a bicyclist was j...|    0|[a, bicyclist, wa...|[a, bicyclist, wa...|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_stem.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new pipline\n",
    "idf                 = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=2.0)\n",
    "lr                  = LogisticRegression(maxIter=20)\n",
    "\n",
    "stemming_pipeline2  = Pipeline(stages= [tf3, idf, lr])\n",
    "\n",
    "# fit and get predictions\n",
    "model4         = stemming_pipeline2.fit(train_stem)\n",
    "predictions4   = model4.transform(test_stem)\n",
    "score4         = evaluator.evaluate(predictions4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORE: 0.88040135203641\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC SCORE: {}\".format(score4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams And Parameter Tunning With Cross Validation <a class=\"anchor\" id=\"bullet6\"></a>\n",
    "--------------------\n",
    "\n",
    "### bigrams, no stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import NGram\n",
    "\n",
    "bigram = NGram(inputCol=\"tokens\", outputCol=\"bigrams\", n=2)\n",
    "\n",
    "tf5   = HashingTF(inputCol=\"bigrams\", outputCol=\"rawFeatures\", numFeatures=2e5)\n",
    "\n",
    "bigram_pipeline  = Pipeline(stages= [tk, bigram, tf5, idf, lr])\n",
    "\n",
    "model5           = bigram_pipeline.fit(train)\n",
    "predictions5     = model5.transform(test)\n",
    "\n",
    "score5           = evaluator.evaluate(predictions5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORE: 0.890927326083407\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC SCORE: {}\".format(score5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bigrams, with stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import NGram\n",
    "\n",
    "bigram2 = NGram(inputCol=\"stemmed\", outputCol=\"bigrams\", n=2)\n",
    "\n",
    "tf6  = HashingTF(inputCol=\"bigrams\", outputCol=\"rawFeatures\", numFeatures=2e5)\n",
    "\n",
    "idf    = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=2.0)\n",
    "\n",
    "lr     = LogisticRegression(maxIter=20)\n",
    "\n",
    "stem_bigram_pipeline  = Pipeline(stages= [bigram2, tf6, idf, lr])\n",
    "\n",
    "model6                = stem_bigram_pipeline.fit(train_stem)\n",
    "predictions6          = model6.transform(test_stem)\n",
    "\n",
    "score6                = evaluator.evaluate(predictions6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "hiddenCell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|         tweet_clean|              tokens|             stemmed|             bigrams|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|a and yr old both...|[a, and, yr, old,...|[a, and, yr, old,...|[a and, and yr, y...|\n",
      "|a baby bird fell ...|[a, baby, bird, f...|[a, babi, bird, f...|[a babi, babi bir...|\n",
      "|a baby llama was ...|[a, baby, llama, ...|[a, babi, llama, ...|[a babi, babi lla...|\n",
      "|a beautiful day t...|[a, beautiful, da...|[a, beauti, day, ...|[a beauti, beauti...|\n",
      "|a bicyclist was j...|[a, bicyclist, wa...|[a, bicyclist, wa...|[a bicyclist, bic...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions6.select([\"tweet_clean\",\"tokens\",\"stemmed\",\"bigrams\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORE: 0.8929975456358279\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC SCORE: {}\".format(score6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "bigram2 = NGram(inputCol=\"stemmed\", outputCol=\"bigrams\", n=2)\n",
    "\n",
    "tf6  = HashingTF(inputCol=\"bigrams\", outputCol=\"rawFeatures\", numFeatures=2e5)\n",
    "\n",
    "idf    = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "lr     = LogisticRegression(maxIter=20)\n",
    "\n",
    "stem_bigram_pipeline  = Pipeline(stages= [bigram2, tf6, idf, lr])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "                        .addGrid(idf.minDocFreq, [2, 5]) \\\n",
    "                        .addGrid(lr.regParam, [0.0, 0.1]) \\\n",
    "                        .build()\n",
    "     \n",
    "crossval = CrossValidator(estimator          = stem_bigram_pipeline,\n",
    "                          estimatorParamMaps = paramGrid,\n",
    "                          evaluator          = BinaryClassificationEvaluator(),\n",
    "                          numFolds           = 3)\n",
    "\n",
    "model    = crossval.fit(train_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions   = model.transform(test_stem)\n",
    "\n",
    "score         = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORE: 0.8914174745931814\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC SCORE: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedAndLabels = predictions.select([\"prediction\",\"label\"])\\\n",
    "                                .rdd.map(lambda r : (float(r[0]), float(r[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.8153407934893184\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "metrics = MulticlassMetrics(predictedAndLabels)\n",
    "\n",
    "print(\"Test Set Accuracy: {}\".format(metrics.accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>TrainValidationSplit</code> only evaluates each parameter choice once instead of multiple times over each of the $K$ fold in <code>CrossValidator</code>.  Therefore this estimator is not as expensive as cross validation,\n",
    "but can produce less reliable results when dataset isn't large enough.  See the <a href=\"https://spark.apache.org/docs/latest/ml-tuning.html#train-validation-split\">documenation</a> for more infromation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NGram_40759d058add92d09ae5,\n",
       " HashingTF_4a6e8ba9ed3f963b503d,\n",
       " IDF_46d39c742a5e256dfe52,\n",
       " LogisticRegression_452b8fd5858100e48a64]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'minDocFreq: minimum number of documents in which a term should appear for filtering (>= 0) (default: 0, current: 5)'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.stages[2].explainParam('minDocFreq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'regParam: regularization parameter (>= 0) (default: 0.0, current: 0.1)'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.stages[-1].explainParam('regParam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = bestModel.stages[-1].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f93383b9b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.plot(summary.roc.select('FPR').collect(),\n",
    "         summary.roc.select('TPR').collect())\n",
    "plt.xlabel('False Positive Rare')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions <a class=\"anchor\" id=\"bullet7\"></a>\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
